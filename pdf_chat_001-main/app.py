# app.py
# ç¨ç†å£«äº‹å‹™æ‰€å‘ã‘ï¼šStreamlit + Google Drive + Pinecone v3 + Gemini ã‚’ç”¨ã„ãŸPDFè³ªå•Bot

import os
import io
import fitz  # PyMuPDF
import streamlit as st
import requests
from google.oauth2 import service_account
from googleapiclient.discovery import build
from googleapiclient.http import MediaIoBaseDownload
from langchain.text_splitter import RecursiveCharacterTextSplitter
from langchain.embeddings import OpenAIEmbeddings
from pinecone import Pinecone, ServerlessSpec

# --- ãƒãƒ¼ã‚¸ãƒ§ãƒ³ç¢ºèªï¼ˆsidebarã«è¡¨ç¤ºï¼‰ ---
import langchain
import openai
st.sidebar.markdown(f"ğŸ§ª Langchain: {langchain.__version__}")
st.sidebar.markdown(f"ğŸ§ª OpenAI: {openai.__version__}")

# --- ãƒšãƒ¼ã‚¸è¨­å®š ---
st.set_page_config(page_title="ç¨ç†å£«äº‹å‹™æ‰€å‘ã‘ PDF QA Bot", layout="wide")

# --- Secretsèª­ã¿è¾¼ã¿ï¼ˆã‚¨ãƒ©ãƒ¼ãƒãƒ³ãƒ‰ãƒªãƒ³ã‚°ä»˜ãï¼‰ ---
try:
    GEMINI_API_KEY = st.secrets["API_KEY"]
    PINECONE_API_KEY = st.secrets["PINECONE_API_KEY"]
    PINECONE_ENV = st.secrets["PINECONE_ENV"]
    OPENAI_API_KEY = st.secrets["OPENAI_API_KEY"]
    PDF_FOLDER_ID = st.secrets["PDF_FOLDER_ID"]
    info = st.secrets["service_account"]
except Exception as e:
    st.error("âŒ secrets.toml ã«å¿…è¦ãªè¨­å®šãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“ã€‚")
    st.stop()

# --- Google Drive API èªè¨¼ ---
credentials = service_account.Credentials.from_service_account_info(info, scopes=["https://www.googleapis.com/auth/drive.readonly"])
drive_service = build("drive", "v3", credentials=credentials)

# --- Pinecone åˆæœŸåŒ–ï¼ˆv3ï¼‰ ---
pc = Pinecone(api_key=PINECONE_API_KEY)
if "pdf-index" not in pc.list_indexes().names():
    pc.create_index(
        name="pdf-index",
        dimension=1536,
        metric="cosine",
        spec=ServerlessSpec(cloud="aws", region="us-west-2")  # åœ°åŸŸã¯é©å®œèª¿æ•´
    )
index = pc.Index("pdf-index")

# --- Drive PDF â†’ ãƒ†ã‚­ã‚¹ãƒˆæŠ½å‡º ---
def extract_text_from_drive_pdf(file_id):
    request = drive_service.files().get_media(fileId=file_id)
    fh = io.BytesIO()
    downloader = MediaIoBaseDownload(fh, request)
    done = False
    while not done:
        status, done = downloader.next_chunk()
    fh.seek(0)
    doc = fitz.open(stream=fh.read(), filetype="pdf")
    return "\n".join([page.get_text() for page in doc])

# --- PDFãƒ•ã‚¡ã‚¤ãƒ«ã®ã‚¤ãƒ³ãƒ‡ãƒƒã‚¯ã‚¹åŒ–å‡¦ç† ---
def index_pdfs():
    results = drive_service.files().list(q=f"'{PDF_FOLDER_ID}' in parents and mimeType='application/pdf'", fields="files(id, name)").execute()
    files = results.get("files", [])
    splitter = RecursiveCharacterTextSplitter(chunk_size=500, chunk_overlap=100)
    embedder = OpenAIEmbeddings(openai_api_key=OPENAI_API_KEY)

    for file in files:
        file_id = file["id"]
        file_name = file["name"]
        text = extract_text_from_drive_pdf(file_id)
        if not text.strip():
            st.warning(f"âš  ç©ºã®PDF ({file_name}) ã¯ã‚¹ã‚­ãƒƒãƒ—ã—ã¾ã—ãŸã€‚")
            continue
        chunks = splitter.split_text(text)
        vectors = embedder.embed_documents(chunks)
        ids = [f"{file_name}-{i}" for i in range(len(chunks))]
        metadata = [{"text": chunk, "source": file_name} for chunk in chunks]
        index.upsert(vectors=zip(ids, vectors, metadata))

# --- Geminiã§ã®å¿œç­”ç”Ÿæˆ ---
def query_gemini(context, question):
    prompt = f"""ä»¥ä¸‹ã®ç¨å‹™é–¢é€£è³‡æ–™ã«åŸºã¥ã„ã¦è³ªå•ã«ç­”ãˆã¦ãã ã•ã„:\n\n{context}\n\nè³ªå•: {question}"""
    payload = {"contents": [{"parts": [{"text": prompt}]}]}
    url = f"https://generativelanguage.googleapis.com/v1/models/gemini-1.5-pro:generateContent?key={GEMINI_API_KEY}"
    res = requests.post(url, json=payload)
    try:
        return res.json()['candidates'][0]['content']['parts'][0]['text']
    except Exception:
        return f"âŒ Gemini APIã®ãƒ¬ã‚¹ãƒãƒ³ã‚¹è§£æã«å¤±æ•—ã—ã¾ã—ãŸ: {res.text}"

# --- Streamlit UI ---
st.title("ğŸ§¾ ç¨ç†å£«äº‹å‹™æ‰€å‘ã‘ PDF QA Bot")

if st.button("ğŸ“¥ Driveã®PDFã‚’ã‚¤ãƒ³ãƒ‡ãƒƒã‚¯ã‚¹åŒ–"):
    with st.spinner("PDFã‚’èª­ã¿è¾¼ã¿ã€ãƒ™ã‚¯ãƒˆãƒ«åŒ–ã—ã¦Pineconeã«ç™»éŒ²ä¸­..."):
        index_pdfs()
        st.success("âœ… ã‚¤ãƒ³ãƒ‡ãƒƒã‚¯ã‚¹åŒ–ãŒå®Œäº†ã—ã¾ã—ãŸ")

question = st.text_input("â“ è³ªå•ã‚’å…¥åŠ›ã—ã¦ãã ã•ã„ï¼ˆä¾‹ï¼šã€æ˜¨å¹´åº¦ã®æ³•äººç¨ç”³å‘Šæ›¸ã®æ§é™¤é¡ã¯ï¼Ÿã€ï¼‰")

if question:
    embedder = OpenAIEmbeddings(openai_api_key=OPENAI_API_KEY)
    query_vector = embedder.embed_query(question)
    results = index.query(vector=query_vector, top_k=5, include_metadata=True)
    context_chunks = results.get("matches", [])
    if not context_chunks:
        st.error("ğŸ” é–¢é€£ã™ã‚‹æƒ…å ±ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“ã§ã—ãŸã€‚")
    else:
        context = "\n".join([match["metadata"]["text"] for match in context_chunks])
        with st.spinner("ğŸ’¬ Geminiã«å•ã„åˆã‚ã›ä¸­..."):
            answer = query_gemini(context, question)
            st.markdown("### ğŸ§  å›ç­”")
            st.write(answer)
            with st.expander("ğŸ“š å‚ç…§ã•ã‚ŒãŸè³‡æ–™ã®ä¸€éƒ¨"):
                for match in context_chunks:
                    st.markdown(f"ğŸ“„ **{match['metadata']['source']}** ã‚ˆã‚Š:\n\n{match['metadata']['text'][:500]}...")
